positive = "1")
print(conf_matrix_treino_nb)
# Extração de precisão e recall da matriz de confusão
precision_treino_nb <- conf_matrix_treino_nb$byClass["Pos Pred Value"]  # Precisão
recall_treino_nb <- conf_matrix_treino_nb$byClass["Sensitivity"]        # Recall
# Imprimindo os resultados de precisão e recall
print(paste("Naive Bayes - Precisão (treino):", precision_treino_nb))
print(paste("Naive Bayes - Recall (treino):", recall_treino_nb))
# Selecionar apenas as variáveis usadas no conjunto de dados de treino
teste_restrito <- teste[, vars_usadas]
# Verificar se as variáveis estão corretas
print(colnames(teste_restrito))
# Avaliação na base de teste
preditos_teste_nb <- predict(nb_model, newdata = teste_restrito, type = "class")
# Verificar os níveis dos fatores
levels(preditos_teste_nb)
levels(teste$ativo)
# Reordenar os níveis de preditos_teste_nb para corresponder aos níveis de teste$ativo
preditos_teste_nb <- factor(preditos_teste_nb, levels = levels(teste$ativo))
# Matriz de confusão para o conjunto de teste
conf_matrix_teste_nb <- confusionMatrix(data = preditos_teste_nb,
reference = teste$ativo,
positive = "1")
print(conf_matrix_teste_nb)
# Extração de precisão e recall da matriz de confusão
precision_teste_nb <- conf_matrix_teste_nb$byClass["Pos Pred Value"]  # Precisão
recall_teste_nb <- conf_matrix_teste_nb$byClass["Sensitivity"]        # Recall
# Imprimindo os resultados de precisão e recall
print(paste("Naive Bayes - Precisão (teste):", precision_teste_nb))
print(paste("Naive Bayes - Recall (teste):", recall_teste_nb))
str(preditos_treino_nb)
#Função para plotar matriz de confusão
plot_confusion <- function(confusionMatrix, title) {
conf_df <- as.data.frame(confusionMatrix$table)
conf_df$Reference <- factor(conf_df$Reference, levels = c("0", "1"))
conf_df$Prediction <- factor(conf_df$Prediction, levels = c("0", "1"))
ggplot(data = conf_df, aes(x = Reference, y = Prediction, fill = as.factor(Freq))) +
geom_tile() +
geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
labs(x = "Valor Real", y = "Valor Previsto", fill = "Contagem", title = title) +
scale_fill_gradient(low = "white", high = "blue", na.value = "grey50", aesthetics = "colour") +  # Ajuste na escala de cores
theme_bw() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
# Plot da matriz de confusão para o conjunto de treino e teste
plot_confusion(conf_matrix_treino_nb, "Matriz de Confusão - Treino NB")
plot_confusion(conf_matrix_teste_nb, "Matriz de Confusão - Teste NB")
# Converter preditos_treino_nb de fator para numérico
preditos_treino_nb_numeric <- as.numeric(as.character(preditos_treino_nb))
# Calcular a curva ROC
ROC_nb <- roc(response = as.numeric(treino$ativo),
predictor = preditos_treino_nb_numeric)
# Calcular a AUC
valor_auc_treino_nb <- auc(ROC_nb)
# Criar um data frame para plotagem da curva ROC
roc_data <- data.frame(
specificity = 1 - ROC_nb$specificities,
sensitivity = ROC_nb$sensitivities
)
# Plot da curva ROC
plotROC <- ggplot(data = roc_data, aes(x = specificity, y = sensitivity)) +
geom_line(color = "blue") +
geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +
labs(x = "1 - Especificidade",
y = "Sensitividade",
title = paste("Curva ROC Treino NB (AUC =", round(valor_auc_treino_nb, 3), ")")) +
theme_bw()
# Exibir o gráfico
print(plotROC)
# Calcular a curva ROC TESTE
# Converter preditos_treino_nb de fator para numérico
preditos_teste_nb_numeric <- as.numeric(as.character(preditos_teste_nb))
# Calcular a curva ROC
ROC_nb <- roc(response = as.numeric(teste$ativo),
predictor = preditos_teste_nb_numeric)
# Calcular a AUC
valor_auc_teste_nb <- auc(ROC_nb)
# Criar um data frame para plotagem da curva ROC
roc_data <- data.frame(
specificity = 1 - ROC_nb$specificities,
sensitivity = ROC_nb$sensitivities
)
# Plot da curva ROC
plotROC <- ggplot(data = roc_data, aes(x = specificity, y = sensitivity)) +
geom_line(color = "blue") +
geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +
labs(x = "1 - Especificidade",
y = "Sensitividade",
title = paste("Curva ROC Teste NB (AUC =", round(valor_auc_teste_nb, 3), ")")) +
theme_bw()
# Exibir o gráfico
print(plotROC)
library(caret)
library(randomForest)
treino$vendas_30_dias <- as.integer(as.character(treino$vendas_30_dias))
teste$vendas_30_dias <- as.integer(as.character(teste$vendas_30_dias))
treino$pedidos_30_dias <- as.integer(as.character(treino$pedidos_30_dias))
teste$pedidos_30_dias <- as.integer(as.character(teste$pedidos_30_dias))
# Usar drop_na() para remover linhas com NAs
treino <- drop_na(treino)
teste <- drop_na(teste)
# Verificar se ainda há valores ausentes
sum(is.na(treino))  # Deve retornar 0
sum(is.na(teste))   # Deve retornar 0
# Ajustar o modelo Random Forest
set.seed(100)
random_forest <- randomForest(ativo ~ .,
data = treino,
importance = TRUE,
ntree = 200,
mtry = 2)
# Definir a semente para reproducibilidade
set.seed(100)
random_forest <- randomForest(ativo ~.,
data = treino,
importance=TRUE,
ntree = 200,
mtry = 2)
# "importance": para retornar a importância das variáveis X no modelo
# "ntree": número de árvores a serem geradas
# "mtry": número de variáveis amostradas aleatoriamente para tentar cada divisão
### o valor de mtry não pode exceder a quantidade de variáveis X
# Dois outros possíveis hiperparâmetros relacionados às árvores:
## "nodesize": tamanho mínimo dos nós folha
## "maxnodes": número máximo de nós folha que a árvore pode ter
# Calcular as previsões de classe para o conjunto de treino
preditos_treino_rf_class <- predict(random_forest, newdata = treino, type = "response")
# Calcular as probabilidades preditas para a classe positiva (ativo = 1)
preditos_treino_rf_prob <- predict(random_forest, newdata = treino, type = "prob")
## Note que não foi estabelecido um cutoff (o algoritmo usou o padrão)
# Matriz de confusão para a amostra de treino
conf_matrix_treino_rf <- confusionMatrix(preditos_treino_rf_class, treino$ativo, positive = "1")
print(conf_matrix_treino_rf)
# Extração de precisão e recall da matriz de confusão
precision_treino_rf <- conf_matrix_treino_rf$byClass["Pos Pred Value"]  # Precisão
recall_treino_rf <- conf_matrix_treino_rf$byClass["Sensitivity"]        # Recall
# Imprimindo os resultados de precisão e recall
print(paste("Precisão:", precision_treino))
print(paste("Recall:", recall_treino))
# Carregar pacotes
library(pROC)
library(ggplot2)
library(plotly)
# Calcular a curva ROC
roc_curve <- roc(response = treino$ativo,
predictor = preditos_treino_rf_prob[, 2])
# AUC da classe positiva (ativo = 1)
valor_auc_treino_rf <- roc_curve$auc
# Imprimir o valor do AUC
print(paste("Área abaixo da curva (AUC):", round(valor_auc_treino_rf, 5)))
# Plot da curva ROC
plot(roc_curve, main = paste("Curva ROC Treino RF (AUC):", round(valor_auc_treino_rf, 5)), col = "red")
# Investigando se há overfitting
# Calcular as previsões de classe para o conjunto de teste
preditos_teste_rf_class <- predict(random_forest, newdata = teste, type = "response")
# Calcular as probabilidades preditas para a classe positiva (ativo = 1)
preditos_teste_rf_prob <- predict(random_forest, newdata = teste, type = "prob")
# Verificar os níveis dos fatores
levels(preditos_teste_rf_class)
levels(teste$ativo)
# Ajustar os níveis dos valores preditos para corresponder aos níveis do conjunto de teste
preditos_teste_rf_class <- factor(preditos_teste_rf_class, levels = levels(teste$ativo))
# Calcular a matriz de confusão para a amostra de teste
conf_matrix_teste_rf <- confusionMatrix(data = preditos_teste_rf_class,
reference = teste$ativo,
positive = "1")
# Exibir a matriz de confusão e as estatísticas associadas
print(conf_matrix_teste_rf)
# Extração de precisão e recall da matriz de confusão
precision_teste_rf <- conf_matrix_teste_rf$byClass["Pos Pred Value"]  # Precisão
recall_teste_rf <- conf_matrix_teste_rf$byClass["Sensitivity"]        # Recall
# Imprimindo os resultados de precisão e recall
print(paste("Precisão:", precision_treino))
print(paste("Recall:", recall_treino))
# Calcular a curva ROC
roc_curve <- roc(response = teste$ativo,
predictor = preditos_teste_rf_prob[, 2])
# AUC da classe positiva (ativo = 1)
valor_auc_teste_rf <- roc_curve$auc
# Imprimir o valor do AUC
print(paste("Área abaixo da curva (AUC):", round(valor_auc_teste_rf, 5)))
# Plot da curva ROC
plot(roc_curve, main = paste("Curva ROC Teste RF (AUC):", round(valor_auc_teste_rf, 5)), col = "red")
#Função para plotar matriz de confusão
plot_confusion <- function(confusionMatrix, title) {
conf_df <- as.data.frame(confusionMatrix$table)
conf_df$Reference <- factor(conf_df$Reference, levels = c("0", "1"))
conf_df$Prediction <- factor(conf_df$Prediction, levels = c("0", "1"))
ggplot(data = conf_df, aes(x = Reference, y = Prediction, fill = as.factor(Freq))) +
geom_tile() +
geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
labs(x = "Valor Real", y = "Valor Previsto", fill = "Contagem", title = title) +
scale_fill_gradient(low = "white", high = "blue", na.value = "grey50", aesthetics = "colour") +  # Ajuste na escala de cores
theme_bw() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
# Plot da matriz de confusão para o conjunto de treino e teste
plot_confusion(conf_matrix_treino_rf, "Matriz de Confusão - Treino RF")
plot_confusion(conf_matrix_teste_rf, "Matriz de Confusão - Teste RF")
# Imprimindo os resultados de precisão e recall
print(paste("Precisão:", precision_treino_rf))
print(paste("Recall:", recall_treino_rf))
# Extração de precisão e recall da matriz de confusão
precision_teste_rf <- conf_matrix_teste_rf$byClass["Pos Pred Value"]  # Precisão
recall_teste_rf <- conf_matrix_teste_rf$byClass["Sensitivity"]        # Recall
# Imprimindo os resultados de precisão e recall
print(paste("Precisão:", precision_treino_rf))
print(paste("Recall:", recall_treino_rf))
# Extração de precisão e recall da matriz de confusão
precision_teste_rf <- conf_matrix_teste_rf$byClass["Pos Pred Value"]  # Precisão
recall_teste_rf <- conf_matrix_teste_rf$byClass["Sensitivity"]        # Recall
# Imprimindo os resultados de precisão e recall
print(paste("Precisão:", precision_teste_rf))
print(paste("Recall:", recall_teste_rf))
# Confusion Matrix
conf_matrix <- c(
treino_arvore = conf_matrix_treino$overall["Accuracy"],
teste_arvore = conf_matrix_teste$overall["Accuracy"],
treino_nb = conf_matrix_treino_nb$overall["Accuracy"],
teste_nb = conf_matrix_teste_nb$overall["Accuracy"],
treino_rf = conf_matrix_treino_rf$overall["Accuracy"],
teste_rf = conf_matrix_teste_rf$overall["Accuracy"])
print (conf_matrix)
#Auc
auc <- list(
treino_arvore = valor_auc_treino_arvore,
teste_arvore = valor_auc_teste_arvore,
treino_nb = valor_auc_treino_nb,
teste_nb = valor_auc_teste_nb,
treino_rf = valor_auc_treino_rf,
teste_rf = valor_auc_teste_rf)
# Precision e Recall
precision <- c(
treino_arvore = precision_treino,
teste_arvore = precision_teste,
treino_nb = precision_treino_nb,
teste_nb = precision_teste_nb,
treino_rf = precision_treino_rf,
teste_rf = precision_teste_rf)
print(precision)
recall <- c(
treino_arvore = recall_treino,
teste_arvore = recall_teste,
treino_nb = recall_treino_nb,
teste_nb = recall_teste_nb,
treino_rf = recall_treino_rf,
teste_rf = recall_teste_rf
)
print(recall)
precision <- c( 0.9488152, 0.8488121, 0.9572271, 0.9403509, 0.9979360, 0.8758782)
recall <- c(0.9345622, 0.8451613, 0.5981567, 0.5763441,  0.9641077, 0.9012048)
AUC <- c(0.96, 0.854,0.781,0.764,0.99697,0.93474)
# Construção do data frame resultados
resultados <- data.frame(
Modelo = rep(c("Árvore de Decisão", "Naive Bayes", "Random Forest"), each = 2),
Métrica = rep(c("Precisão", "Recall, AUC"), 3),  # Repetir 2 vezes para cada métrica
Conjunto = rep(c("Treino", "Teste"), each = 6),  # Repetir 3 modelos x 2 métricas x 2 conjuntos
Valor = c(
precision[1], recall[1],AUC[1],  # Árvore de Decisão, Precisão e Recall Treino
precision[2], recall[2],AUC[2],  # Árvore de Decisão, Precisão e Recall Teste
precision[3], recall[3],AUC[3], # Naive Bayes, Precisão e Recall Treino
precision[4], recall[4],AUC[4],  # Naive Bayes, Precisão e Recall Teste
precision[5], recall[5],AUC[5],  # Random Forest, Precisão e Recall Treino
precision[6], recall[6],AUC[6]   # Random Forest, Precisão e Recall Teste
)
)
# Construção do data frame resultados
resultados <- data.frame(
Modelo = rep(c("Árvore de Decisão", "Naive Bayes", "Random Forest"), each = 2),
Métrica = rep(c("Precisão", "Recall, AUC"), 4),  # Repetir 2 vezes para cada métrica
Conjunto = rep(c("Treino", "Teste"), each = 6),  # Repetir 3 modelos x 2 métricas x 2 conjuntos
Valor = c(
precision[1], recall[1],AUC[1],  # Árvore de Decisão, Precisão e Recall Treino
precision[2], recall[2],AUC[2],  # Árvore de Decisão, Precisão e Recall Teste
precision[3], recall[3],AUC[3], # Naive Bayes, Precisão e Recall Treino
precision[4], recall[4],AUC[4],  # Naive Bayes, Precisão e Recall Teste
precision[5], recall[5],AUC[5],  # Random Forest, Precisão e Recall Treino
precision[6], recall[6],AUC[6]   # Random Forest, Precisão e Recall Teste
)
sum(is.na(resultados$Valor))
# Construção do data frame resultados
resultados <- data.frame(
Modelo = rep(c("Árvore de Decisão", "Naive Bayes", "Random Forest"), each = 2),
Métrica = rep(c("Precisão", "Recall, AUC"), 4),  # Repetir 2 vezes para cada métrica
Conjunto = rep(c("Treino", "Teste"), each = 6),  # Repetir 3 modelos x 2 métricas x 2 conjuntos
Valor = c(
precision[1], recall[1],AUC[1],  # Árvore de Decisão, Precisão e Recall Treino
precision[2], recall[2],AUC[2],  # Árvore de Decisão, Precisão e Recall Teste
precision[3], recall[3],AUC[3], # Naive Bayes, Precisão e Recall Treino
precision[4], recall[4],AUC[4],  # Naive Bayes, Precisão e Recall Teste
precision[5], recall[5],AUC[5],  # Random Forest, Precisão e Recall Treino
precision[6], recall[6],AUC[6]   # Random Forest, Precisão e Recall Teste
)
)
# Construção do data frame resultados
resultados <- data.frame(
Modelo = rep(c("Árvore de Decisão", "Naive Bayes", "Random Forest"), each = 4),  # 4 métricas (Precisão e Recall para Treino e Teste)
Métrica = rep(c("Precisão Treino", "Recall Treino", "AUC Treino", "Precisão Teste", "Recall Teste", "AUC Teste"), times = 3),
Valor = c(
precision[1], recall[1], AUC[1],  # Árvore de Decisão, Precisão, Recall e AUC
precision[2], recall[2], AUC[2],
precision[3], recall[3], AUC[3],
precision[4], recall[4], AUC[4],
precision[5], recall[5], AUC[5],
precision[6], recall[6], AUC[6]
)
)
# Construção do data frame resultados
resultados <- data.frame(
Modelo = rep(c("Árvore de Decisão", "Naive Bayes", "Random Forest"), each = 4),  # 4 métricas (Precisão e Recall para Treino e Teste)
Métrica = rep(c("Precisão Treino", "Recall Treino", "AUC Treino", "Precisão Teste", "Recall Teste", "AUC Teste"), times = 2),
Valor = c(
precision[1], recall[1], AUC[1],  # Árvore de Decisão, Precisão, Recall e AUC
precision[2], recall[2], AUC[2],
precision[3], recall[3], AUC[3],
precision[4], recall[4], AUC[4],
precision[5], recall[5], AUC[5],
precision[6], recall[6], AUC[6]
)
)
resultados <- data.frame(
Modelo = rep(c("Árvore de Decisão", "Naive Bayes", "Random Forest"), each = 6),  # 6 métricas
Métrica = rep(c("Precisão Treino", "Recall Treino", "AUC Treino", "Precisão Teste", "Recall Teste", "AUC Teste"), times = 3),
Valor = c(
precision[1], recall[1], AUC[1],  # Árvore de Decisão
precision[2], recall[2], AUC[2],
precision[3], recall[3], AUC[3],
precision[4], recall[4], AUC[4],
precision[5], recall[5], AUC[5],
precision[6], recall[6], AUC[6]
)
)
sum(is.na(resultados$Valor))
# Plotar gráfico comparativo
library(ggplot2)
library(dplyr)
ggplot(resultados, aes(x = Modelo, y = Valor, fill = Conjunto)) +
geom_bar(stat = "identity", position = position_dodge()) +
facet_grid(. ~ Métrica, scales = "free_y") +  # Permitir escalas livres em y para cada facet
labs(x = "Modelo", y = "Valor", fill = "Conjunto") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
resultados <- data.frame(
resultados <- data.frame(
Modelo = rep(c("Árvore de Decisão", "Naive Bayes", "Random Forest"), each = 6),
Métrica = rep(c("Precisão Treino", "Recall Treino", "AUC Treino", "Precisão Teste", "Recall Teste", "AUC Teste"), times = 3),
Conjunto = rep(c("Treino", "Teste", "Treino", "Teste", "Treino", "Teste"), times = 3),  # Adicionando a coluna Conjunto
Valor = c(
precision[1], recall[1], AUC[1],
precision[2], recall[2], AUC[2],
precision[3], recall[3], AUC[3],
precision[4], recall[4], AUC[4],
precision[5], recall[5], AUC[5],
precision[6], recall[6], AUC[6]
)
)
sum(is.na(resultados$Valor))
resultados <- data.frame(
resultados <- data.frame(
Modelo = rep(c("Árvore de Decisão", "Naive Bayes", "Random Forest"), each = 6),
Métrica = rep(c("Precisão Treino", "Recall Treino", "AUC Treino", "Precisão Teste", "Recall Teste", "AUC Teste"), times = 3),
Conjunto = rep(c("Treino", "Teste", "Treino", "Teste", "Treino", "Teste"), times = 3),  # Adicionando a coluna Conjunto
Valor = c(
precision[1], recall[1], AUC[1],
precision[2], recall[2], AUC[2],
precision[3], recall[3], AUC[3],
precision[4], recall[4], AUC[4],
precision[5], recall[5], AUC[5],
precision[6], recall[6], AUC[6]
)
))
sum(is.na(resultados$Valor))
ggplot(resultados, aes(x = Modelo, y = Valor, fill = Conjunto)) +
geom_bar(stat = "identity", position = position_dodge()) +
facet_grid(. ~ Métrica, scales = "free_y") +  # Permitir escalas livres em y para cada facet
labs(x = "Modelo", y = "Valor", fill = "Conjunto") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Calcular métricas para os diferentes modelos
# Supondo que você já tenha as variáveis necessárias calculadas para cada modelo
# Confusion Matrix
conf_matrix <- c(
treino_arvore = conf_matrix_treino$overall["Accuracy"],
teste_arvore = conf_matrix_teste$overall["Accuracy"],
treino_nb = conf_matrix_treino_nb$overall["Accuracy"],
teste_nb = conf_matrix_teste_nb$overall["Accuracy"],
treino_rf = conf_matrix_treino_rf$overall["Accuracy"],
teste_rf = conf_matrix_teste_rf$overall["Accuracy"]
)
print(conf_matrix)
# AUC
auc <- list(
treino_arvore = valor_auc_treino_arvore,
teste_arvore = valor_auc_teste_arvore,
treino_nb = valor_auc_treino_nb,
teste_nb = valor_auc_teste_nb,
treino_rf = valor_auc_treino_rf,
teste_rf = valor_auc_teste_rf
)
# Precision e Recall
precision <- c(
treino_arvore = precision_treino,
teste_arvore = precision_teste,
treino_nb = precision_treino_nb,
teste_nb = precision_teste_nb,
treino_rf = precision_treino_rf,
teste_rf = precision_teste_rf
)
print(precision)
recall <- c(
treino_arvore = recall_treino,
teste_arvore = recall_teste,
treino_nb = recall_treino_nb,
teste_nb = recall_teste_nb,
treino_rf = recall_treino_rf,
teste_rf = recall_teste_rf
)
print(recall)
# Definindo as métricas com valores de exemplo
precision <- c(0.9488152, 0.8488121, 0.9572271, 0.9403509, 0.9979360, 0.8758782)
recall <- c(0.9345622, 0.8451613, 0.5981567, 0.5763441, 0.9641077, 0.9012048)
AUC <- c(0.96, 0.854, 0.781, 0.764, 0.99697, 0.93474)
# Construção do data frame resultados
resultados <- data.frame(
Modelo = rep(c("Árvore de Decisão", "Naive Bayes", "Random Forest"), each = 6),
Métrica = rep(c("Precisão Treino", "Recall Treino", "AUC Treino", "Precisão Teste", "Recall Teste", "AUC Teste"), times = 3),
Conjunto = rep(c("Treino", "Treino", "Treino", "Teste", "Teste", "Teste"), times = 3),
Valor = c(
precision[1], recall[1], AUC[1],
precision[2], recall[2], AUC[2],
precision[3], recall[3], AUC[3],
precision[4], recall[4], AUC[4],
precision[5], recall[5], AUC[5],
precision[6], recall[6], AUC[6]
)
)
# Verificar se há NA nos valores
sum(is.na(resultados$Valor))
# Plotar gráfico comparativo
library(ggplot2)
library(dplyr)
ggplot(resultados, aes(x = Modelo, y = Valor, fill = Conjunto)) +
geom_bar(stat = "identity", position = position_dodge()) +
facet_grid(. ~ Métrica, scales = "free_y") +  # Permitir escalas livres em y para cada facet
labs(x = "Modelo", y = "Valor", fill = "Conjunto") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
resultados_auc <- resultados[resultados$Métrica %in% c("AUC Treino", "AUC Teste"), ]
resultados_outros <- resultados[!resultados$Métrica %in% c("AUC Treino", "AUC Teste"), ]
# Gráfico para AUC
ggplot(resultados_auc, aes(x = Modelo, y = Valor, fill = Conjunto)) +
geom_bar(stat = "identity", position = position_dodge()) +
labs(x = "Modelo", y = "AUC", fill = "Conjunto") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Construção do data frame resultados
resultados <- data.frame(
Modelo = rep(c("Árvore de Decisão", "Naive Bayes", "Random Forest"), each = 6),
Métrica = rep(c("Precisão Treino", "Recall Treino", "AUC Treino", "Precisão Teste", "Recall Teste", "AUC Teste"), times = 3),
Conjunto = rep(c("Teste", "Treino", "Teste", "Treino", "Teste", "Treino"), times = 3),
Valor = c(
precision[1], recall[1], AUC[1],
precision[2], recall[2], AUC[2],
precision[3], recall[3], AUC[3],
precision[4], recall[4], AUC[4],
precision[5], recall[5], AUC[5],
precision[6], recall[6], AUC[6]
)
)
resultados_auc <- resultados[resultados$Métrica %in% c("AUC Treino", "AUC Teste"), ]
resultados_outros <- resultados[!resultados$Métrica %in% c("AUC Treino", "AUC Teste"), ]
# Gráfico para AUC
ggplot(resultados_auc, aes(x = Modelo, y = Valor, fill = Conjunto)) +
geom_bar(stat = "identity", position = position_dodge()) +
labs(x = "Modelo", y = "AUC", fill = "Conjunto") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Plotar gráfico comparativo
library(ggplot2)
library(dplyr)
ggplot(resultados, aes(x = Modelo, y = Valor, fill = Conjunto)) +
geom_bar(stat = "identity", position = position_dodge()) +
facet_grid(. ~ Métrica, scales = "free_y") +  # Permitir escalas livres em y para cada facet
labs(x = "Modelo", y = "Valor", fill = "Conjunto") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Definindo as métricas com valores de exemplo
precision <- c(0.9488152, 0.8488121, 0.9572271, 0.9403509, 0.9979360, 0.8758782)
recall <- c(0.9345622, 0.8451613, 0.5981567, 0.5763441, 0.9641077, 0.9012048)
AUC <- c(0.96, 0.854, 0.781, 0.764, 0.99697, 0.93474)
resultados <- data.frame(
Modelo = rep(c("Árvore de Decisão", "Naive Bayes", "Random Forest"), each = 6),
Métrica = rep(c("Precisão Treino", "Recall Treino", "AUC Treino", "Precisão Teste", "Recall Teste", "AUC Teste"), times = 3),
Conjunto = rep(c("Treino", "Teste", "Treino", "Teste", "Treino", "Teste"), times = 3),
Valor = c(
precision[1], recall[1], AUC[1],
precision[2], recall[2], AUC[2],
precision[3], recall[3], AUC[3],
precision[4], recall[4], AUC[4],
precision[5], recall[5], AUC[5],
precision[6], recall[6], AUC[6]
)
)
# Plotar gráfico comparativo
library(ggplot2)
library(dplyr)
ggplot(resultados, aes(x = Modelo, y = Valor, fill = Conjunto)) +
geom_bar(stat = "identity", position = position_dodge()) +
facet_grid(. ~ Métrica, scales = "free_y") +  # Permitir escalas livres em y para cada facet
labs(x = "Modelo", y = "Valor", fill = "Conjunto") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
