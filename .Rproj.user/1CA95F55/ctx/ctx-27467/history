num_cols <- sapply(clientes, is.numeric)
# Ajustar os nomes das colunas se houver caracteres especiais ou espaços
names(clientes) <- make.names(names(clientes))
# Substituir NAs por 0 nas colunas numéricas
clientes[, num_cols] <- lapply(clientes[, num_cols], function(x) ifelse(is.na(x), 0, x))
# Substituir NAs por string vazia nas colunas de caracteres
char_cols <- sapply(clientes, is.character)
clientes[, char_cols] <- lapply(clientes[, char_cols], function(x) ifelse(is.na(x), "", x))
# Substituir NAs por data padrão nas colunas de datas e remover a hora
date_cols <- sapply(clientes, function(x) inherits(x, "Date") | inherits(x, "POSIXct"))
clientes[, date_cols] <- lapply(clientes[, date_cols], function(x) {
if (inherits(x, "Date")) {
as.Date(ifelse(is.na(x), as.Date("1970-01-01"), as.Date(x)))
} else if (inherits(x, "POSIXct")) {
as.Date(ifelse(is.na(x), as.POSIXct("1970-01-01"), as.Date(x)))
} else {
x
}
})
# Lista das variáveis a serem transformadas em fatores
categorical_vars <- c("ativo", "modelo_negocio", "forma_pagamento", "plano_escolhido",
"desconto", "franquia", "UF", "canal", "icp", "plano_pagamento")
# Transformar as variáveis especificadas em fatores
clientes[categorical_vars] <- lapply(clientes[categorical_vars], factor)
# Verificar o resultado
str(clientes)
# Ajustar variáveis qualitativas para fatores
#clientes[] <- lapply(clientes, factor)
# Verificar se a variável resposta tem mais de uma classe, sendo 1 cliente e 0 não cliente
table(clientes$ativo)
# Separação da base de dados em bases de treino e teste
set.seed(100)
#library(caret)
# Criar índices estratificados para divisão de treino/teste
index <- createDataPartition(clientes$ativo, p = 0.70, list = FALSE)
treino <- clientes[index, ]
teste <- clientes[-index, ]
# Ajuste para oversampling da classe minoritária usando ROSE
#library(ROSE)
# Ajuste para oversampling da classe minoritária usando ROSE
oversampled_treino <- ovun.sample(ativo ~ ., data = treino, method = "over", seed = 100)$data
oversampled_treino <- na.omit(oversampled_treino)  # Remover linhas com valores NA
# Gerando a árvore de decisão (árvore de classificação)
set.seed(100)
arvore <- rpart(formula = ativo ~ .,
data = oversampled_treino,
parms = list(split = "gini"),
method = "class",
control = rpart.control(minsplit = 10,
maxdepth = 15,
minbucket = 20,
cp = 0.001))
install.packages("rpart")
install.packages("rpart")
library(rpart)
set.seed(100)
arvore <- rpart(formula = ativo ~ .,
data = oversampled_treino,
parms = list(split = "gini"),
method = "class",
control = rpart.control(minsplit = 10,
maxdepth = 15,
minbucket = 20,
cp = 0.001))
# Previsões no conjunto de treino
preditos_treino <- predict(arvore, treino, type = "prob")
# Definir cutoff para classificação binária (ativa/inativa)
cutoff <- 0.5
# Classificando os valores preditos com base no cutoff
preditos_class <- as.factor(ifelse(preditos_treino[, "1"] >= cutoff, "1", "0"))
table(preditos_class)
# Matriz de confusão para o cutoff estabelecido
conf_matrix_treino <- confusionMatrix(data = preditos_class,
reference = treino$ativo,
positive = "1")
library(rpart)
library(caret)
install.packages("caret")
install.packages("caret")
library(caret)
# Classificando os valores preditos com base no cutoff
preditos_class <- as.factor(ifelse(preditos_treino[, "1"] >= cutoff, "1", "0"))
table(preditos_class)
conf_matrix_treino <- confusionMatrix(data = preditos_class,
reference = treino$ativo,
positive = "1")
precision_treino <- conf_matrix_treino$byClass["Pos Pred Value"]  # Precisão
recall_treino <- conf_matrix_treino$byClass["Sensitivity"]        # Recall
print(paste("Precisão:", precision_treino))
print(paste("Recall:", recall_treino))
plotcp(arvore)
library(rpart.plot)
plotcp(arvore)
printcp(arvore)
# Curva ROC (base de treino)
ROC <- roc(response = as.numeric(treino$ativo),  # Convertendo para binário: "1" -> 1, "0" -> 0
predictor = preditos_treino[, "1"])
library(pROC)
ROC <- roc(response = as.numeric(treino$ativo),  # Convertendo para binário: "1" -> 1, "0" -> 0
predictor = preditos_treino[, "1"])
# AUC
AUC <- round(auc(ROC), 3)
plotROC <- ggplot(data = data.frame(1 - ROC$specificity, ROC$sensitivity),
aes(x = 1 - ROC$specificity, y = ROC$sensitivity)) +
geom_line(color = "blue") +
geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +
labs(x = "1 - Especificidade",
y = "Sensitividade",
title = paste("Curva ROC (AUC =", AUC, ")")) +
theme_bw()
ggplotly(plotROC)
library(plotly)
ggplotly(plotROC)
library(ggplot2)
library(plotly)
# AUC
AUC <- round(auc(ROC), 3)
library(ggplot2)
library(pROC)
# Plot da curva ROC e AUC
plotROC <- ggplot(ROC, aes(x = 1 - specificity, y = sensitivity)) +
geom_line(color = "blue") +
geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +
labs(x = "1 - Especificidade",
y = "Sensitividade",
title = paste("Curva ROC (AUC =", round(ROC$auc, 3), ")")) +
theme_bw()
library(ggplot2)
library(pROC)
# Plot da curva ROC e AUC
plotROC <- ggplot(ROC, aes(x = 1 - specificity, y = sensitivity)) +
geom_line(color = "blue") +
geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +
labs(x = "1 - Especificidade",
y = "Sensitividade",
title = paste("Curva ROC (AUC =", round(ROC$auc, 3), ")")) +
theme_bw()
# Curva ROC (base de treino)
ROC <- roc(response = as.numeric(treino$ativo),  # Convertendo para binário: "1" -> 1, "0" -> 0
predictor = preditos_treino[, "1"])
View(treino)
View(ROC)
# AUC
AUC <- round(auc(ROC), 3)
str(ROC)
plotROC <- ggplot(ROC, aes(x = 1 - specificity, y = sensitivity)) +
geom_line(color = "blue") +
geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +
labs(x = "1 - Especificidade",
y = "Sensitividade",
title = paste("Curva ROC (AUC =", round(ROC$auc, 3), ")")) +
theme_bw()
plotROC <- ggplot(data = data.frame(1 - ROC$specificities, ROC$sensitivities),
aes(x = `1 - ROC$specificities`, y = ROC$sensitivities)) +
geom_line(color = "blue") +
geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +
labs(x = "1 - Especificidade",
y = "Sensitividade",
title = paste("Curva ROC (AUC =", round(ROC$auc, 3), ")")) +
theme_bw()
print(plotROC)
ROC <- roc(response = as.numeric(treino$ativo),  # Convertendo para binário: "1" -> 1, "0" -> 0
predictor = preditos_treino[, "1"])
AUC <- round(auc(ROC), 3)
roc_data <- data.frame(
specificity = 1 - ROC$specificities,
sensitivity = ROC$sensitivities
)
#chamando novamente as bibliotecas
library(ggplot2)
library(pROC)
# Plot da curva ROC e AUC
plotROC <- ggplot(data = data.frame(1 - ROC$specificities, ROC$sensitivities),
aes(x = `1 - ROC$specificities`, y = ROC$sensitivities)) +
geom_line(color = "blue") +
geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +
labs(x = "1 - Especificidade",
y = "Sensitividade",
title = paste("Curva ROC (AUC =", round(ROC$auc, 3), ")")) +
theme_bw()
print(plotROC)
Curva ROC (base de treino)
ROC <- roc(response = as.numeric(treino$ativo),  # Convertendo para binário: "1" -> 1, "0" -> 0
predictor = preditos_treino[, "1"])
plotROC <- ggplot(data = data.frame(1 - ROC$specificities, ROC$sensitivities),
aes(x = `1 - ROC$specificities`, y = ROC$sensitivities)) +
geom_line(color = "blue") +
geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +
labs(x = "1 - Especificidade",
y = "Sensitividade",
title = paste("Curva ROC (AUC =", round(ROC$auc, 3), ")")) +
theme_bw()
print(plotROC)
ROC <- roc(response = as.numeric(treino$ativo),  # Convertendo para binário: "1" -> 1, "0" -> 0
predictor = preditos_treino[, "1"])
roc_data <- data.frame(
specificity = 1 - ROC$specificities,
sensitivity = ROC$sensitivities
)
plotROC <- ggplot(data = data.frame(1 - ROC$specificities, ROC$sensitivities),
aes(x = `1 - ROC$specificities`, y = ROC$sensitivities)) +
geom_line(color = "blue") +
geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +
labs(x = "1 - Especificidade",
y = "Sensitividade",
title = paste("Curva ROC (AUC =", round(ROC$auc, 3), ")")) +
theme_bw()
print(plotROC)
ROC <- roc(response = as.numeric(treino$ativo),  # Convertendo para binário: "1" -> 1, "0" -> 0
predictor = preditos_treino[, "1"])
# Criar um data frame para plotagem da curva ROC
roc_data <- data.frame(
specificity = 1 - ROC$specificities,
sensitivity = ROC$sensitivities
)
# Plot da curva ROC
plotROC <- ggplot(data = roc_data, aes(x = specificity, y = sensitivity)) +
geom_line(color = "blue") +
geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +
labs(x = "1 - Especificidade",
y = "Sensitividade",
title = paste("Curva ROC (AUC =", round(ROC$auc, 3), ")")) +
theme_bw()
# Exibir o plot
print(plotROC)
imp_arvore <- data.frame(importancia = arvore$variable.importance) %>%
rownames_to_column() %>%
arrange(importancia) %>%
rename(variavel = rowname) %>%
mutate(variavel = fct_inorder(variavel))
library(tibble)
imp_arvore <- data.frame(importancia = arvore$variable.importance) %>%
rownames_to_column() %>%
arrange(importancia) %>%
rename(variavel = rowname) %>%
mutate(variavel = fct_inorder(variavel))
library(dplyr)   # Para mutate, arrange, rename
library(forcats)  # Para fct_inorder
imp_arvore <- data.frame(importancia = arvore$variable.importance) %>%
rownames_to_column() %>%
arrange(importancia) %>%
rename(variavel = rowname) %>%
mutate(variavel = fct_inorder(variavel))
# Plotar a importância das variáveis
ggplot(imp_arvore) +
geom_segment(aes(x = variavel, y = 0, xend = variavel, yend = importancia),
linewidth = 1.5, alpha = 0.7) +  # Substituir 'size' por 'linewidth'
geom_point(aes(x = variavel, y = importancia, col = variavel),
size = 4, show.legend = FALSE) +
coord_flip() +
labs(x = "Variável", y = "Importância") +
theme_bw()
# Valores preditos pela árvore (base de teste)
preditos_teste <- predict(arvore, teste)
# Classificando os valores preditos com base no cutoff
preditos_class_teste = factor(ifelse(preditos_teste[,2] > cutoff, 1, 0))
# Matriz de confusão para o cutoff estabelecido na base de teste
conf_matrix_teste <-confusionMatrix(data = preditos_class_teste,
reference = teste$ativo,
positive = "1")
# Extração de precisão e recall da matriz de confusão
precision_teste <- conf_matrix_teste$byClass["Pos Pred Value"]  # Precisão
recall_teste <- conf_matrix_teste$byClass["Sensitivity"]        # Recall
# Imprimindo os resultados de precisão e recall
print(paste("Precisão:", precision_teste))
print(paste("Recall:", recall_teste))
print(paste("Precisão:", precision_teste))
print(paste("Recall:", recall_teste))
# Função para plotar matriz de confusão
plot_confusion <- function(conf_matrix, title) {
conf_df <- as.data.frame(conf_matrix$table)
conf_df$Reference <- factor(conf_df$Reference, levels = c("0", "1"))
conf_df$Prediction <- factor(conf_df$Prediction, levels = c("0", "1"))
ggplot(data = conf_df, aes(x = Reference, y = Prediction, fill = as.factor(Freq))) +
geom_tile() +
geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
labs(x = "Valor Real", y = "Valor Previsto", fill = "Contagem", title = title) +
scale_fill_gradient(low = "white", high = "blue", na.value = "grey50", aesthetics = "colour") +  # Ajuste na escala de cores
theme_bw() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
# Plot da matriz de confusão para o conjunto de treino e teste
plot_confusion(conf_matrix_treino, "Matriz de Confusão - Treino")
plot_confusion(conf_matrix_teste, "Matriz de Confusão - Teste")
library(caret)
library(randomForest)
treino$vendas_30_dias <- as.integer(as.character(treino$vendas_30_dias))
teste$vendas_30_dias <- as.integer(as.character(teste$vendas_30_dias))
set.seed(100)
random_forest <- randomForest(ativo ~.,
data = treino,
importance=TRUE,
ntree = 200,
mtry = 2)
# Calcular as previsões de classe para o conjunto de treino
preditos_treino_rf_class <- predict(random_forest, newdata = treino, type = "response")
# Calcular as probabilidades preditas para a classe positiva (ativo = 1)
preditos_treino_rf_prob <- predict(random_forest, newdata = treino, type = "prob")
# Matriz de confusão para a amostra de treino
confusionMatrix(data = preditos_treino_rf_class,
reference = treino$ativo,
positive = "1")
library(pROC)
library(ggplot2)
library(plotly)
# Curva ROC (amostra de treino)
ROC <- roc(response = treino$ativo,
predictor = preditos_treino_rf_prob[,2])
ggplotly(
ggroc(ROC, color = "red", linewidth = 0.7) +
geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1),
color="grey",
linewidth = 0.2) +
labs(x = "Especificidade",
y = "Sensitividade",
title = paste("Área abaixo da curva (AUC):",
round(ROC$auc, 5))) +
theme_bw())
plotROC <- ggplot(data = data.frame(specificity = ROC$specificities, sensitivity = ROC$sensitivities),
aes(x = 1 - specificity, y = sensitivity)) +
geom_line(color = "red", size = 0.7) +
annotate("segment", x = 0, xend = 1, y = 0, yend = 1, color = "grey", size = 0.2, linetype = "dashed") +
labs(x = "Especificidade",
y = "Sensitividade",
title = paste("Área abaixo da curva (AUC):", round(ROC$auc, 5))) +
theme_bw()
plotROC <- ggplot(data = data.frame(specificity = ROC$specificities, sensitivity = ROC$sensitivities),
aes(x = 1 - specificity, y = sensitivity)) +
geom_line(color = "red", size = 0.7, show.legend = FALSE) +
annotate("segment", x = 0, xend = 1, y = 0, yend = 1, color = "grey", linewidth = 0.2, linetype = "dashed") +
labs(x = "Especificidade",
y = "Sensitividade",
title = paste("Área abaixo da curva (AUC):", round(ROC$auc, 5))) +
theme_bw()
# Plot da curva ROC usando ggplot2
plotROC <- ggplot(data = data.frame(specificity = ROC$specificities, sensitivity = ROC$sensitivities),
aes(x = 1 - specificity, y = sensitivity)) +
geom_line(color = "red", size = 0.7, show.legend = FALSE) +
annotate("segment", x = 0, xend = 1, y = 0, yend = 1, color = "grey", linewidth = 0.2, linetype = "dashed") +
labs(x = "Especificidade",
y = "Sensitividade",
title = paste("Área abaixo da curva (AUC):", round(ROC$auc, 5))) +
theme_bw()
# Converter para plotly
ggplotly(plotROC)
imp_rf <- data.frame(random_forest$importance) %>%
rownames_to_column() %>%
arrange(MeanDecreaseGini) %>%
select(rowname, MeanDecreaseGini) %>%
rename(variavel = rowname, importancia = MeanDecreaseGini) %>%
mutate(variavel = fct_inorder(variavel))
ggplot(imp_rf) +
geom_segment(aes(x = variavel, y = 0, xend = variavel, yend = importancia),
size = 1.5, alpha = 0.7) +
geom_point(aes(x = variavel, y = importancia, col = variavel),
size = 4, show.legend = F) +
coord_flip() +
labs(x = "Variável", y = "Importância") +
theme_bw()
# Investigando se há overfitting
# Valores preditos pela random forest (base de teste)
preditos_teste_rf_class <- predict(random_forest, teste)
# Matriz de confusão para a amostra de teste
confusionMatrix(data = preditos_teste_rf_class,
reference = teste$ativo,
positive = "1")
install.packages("xgboost")
install.packages("caret")
library(xgboost)
library(caret)
# As variáveis precisam ser separadas e colocadas em matrizes
var_dep_treino <- as.matrix(treino[,4])
var_explica_treino <- as.matrix(var_explica_treino)
install.packages("caret")
var_dep_treino <- as.matrix(treino[,4])
var_explica_treino <- as.matrix(var_explica_treino)
var_dep_treino <- as.matrix(treino[, 1])  # Variável de resposta "ativo"
var_explica_treino <- as.matrix(treino[, -1])  # Todas as outras variáveis exceto a primeira (ativo)
class(var_dep_treino)
set.seed(100)
modelo_xgb <- xgb.cv(
data = xgb.DMatrix(data = var_explica_treino, label = var_dep_treino),
nrounds = 100,
eta = 0.10,
max_depth = 7,
nfold = 5,
objective = "binary:logistic",
metrics = "error",
verbose = 0,
early_stopping_rounds = 10
)
# Estimando o modelo inicial
set.seed(100)
library(xgboost)
set.seed(100)
modelo_xgb <- xgb.cv(
data = xgb.DMatrix(data = var_explica_treino, label = var_dep_treino),
nrounds = 100,
eta = 0.10,
max_depth = 7,
nfold = 5,
objective = "binary:logistic",
metrics = "error",
verbose = 0,
early_stopping_rounds = 10
)
set.seed(100)
# Convertendo as variáveis explicativas e dependentes para matrizes
dtrain <- xgb.DMatrix(data = var_explica_treino, label = var_dep_treino)
str(treino)
# As variáveis precisam ser separadas e colocadas em matrizes
var_explica_treino <- select_if(treino, is.numeric) %>%
bind_cols(select_if(treino, is.factor))
library(xgboost)
library(caret)
library(dplyr)
# As variáveis precisam ser separadas e colocadas em matrizes
var_explica_treino <- select_if(treino, is.numeric) %>%
bind_cols(select_if(treino, is.factor))
# Convertendo a variável dependente para numeric (se necessário)
var_dep_treino <- as.numeric(var_dep_treino)
# Verificar a estrutura de var_dep_treino
class(var_dep_treino)
str(treino)
# Criando a matriz DMatrix
dtrain <- xgb.DMatrix(data = as.matrix(var_explica_treino), label = var_dep_treino)
# Criando a matriz DMatrix
dtrain <- xgb.DMatrix(data = as.matrix(var_explica_treino), label = var_dep_treino)
str(var_explica_treino)
# Convertendo a variável dependente para numeric (se necessário)
var_dep_treino <- as.numeric(var_dep_treino)
str(var_explica_treino)
# Convertendo var_explica_treino para matriz numérica
matriz_explica_treino <- as.matrix(var_explica_treino)
# Convertendo var_dep_treino para numeric (se ainda não estiver)
var_dep_treino <- as.numeric(as.character(var_dep_treino))
str(var_explica_treino)
dtrain <- xgb.DMatrix(data = matriz_explica_treino, label = var_dep_treino)
library(naivebayes)
install.packages("naivebayes")
library(naivebayes)
# Ajuste do modelo Naive Bayes
nb_model <- naive_bayes(ativo ~ ., data = oversampled_treino)
# Ajuste do modelo Naive Bayes
nb_model <- naive_bayes(ativo ~ ., data = oversampled_treino, laplace = 1)
# Previsões no conjunto de treino
preditos_treino_nb <- predict(nb_model, treino, type = "raw")
# Prever com o modelo Naive Bayes
preditos_treino_nb <- predict(nb_model, newdata = treino, type = "class")
# Ajuste do modelo Naive Bayes
nb_model <- naive_bayes(ativo ~ ., data = oversampled_treino, laplace = 1)
# Obter as variáveis usadas no modelo
vars_usadas <- colnames(nb_model$tables)
# Selecionar apenas as variáveis usadas no conjunto de dados de treino
treino_restrito <- treino[, vars_usadas]
# Prever com o modelo Naive Bayes usando apenas as variáveis relevantes
preditos_treino_nb <- predict(nb_model, newdata = treino_restrito, type = "class")
# Ajuste do modelo Naive Bayes
nb_model <- naive_bayes(ativo ~ ., data = oversampled_treino, laplace = 1)
# Obter as variáveis usadas no modelo
vars_usadas <- colnames(nb_model$tables)
# Selecionar apenas as variáveis usadas no conjunto de dados de treino
treino_restrito <- treino[, vars_usadas]
# Prever com o modelo Naive Bayes usando apenas as variáveis relevantes
preditos_treino_nb <- predict(nb_model, newdata = treino_restrito, type = "class")
# Verificar se as variáveis estão corretas
print(colnames(treino_restrito))
# Ajuste do modelo Naive Bayes
nb_model <- naive_bayes(ativo ~ ., data = oversampled_treino, laplace = 1)
# Obter as variáveis usadas no modelo
vars_usadas <- colnames(nb_model$tables)
# Verificar as variáveis usadas
print(vars_usadas)
# Ajuste do modelo Naive Bayes
nb_model <- naive_bayes(ativo ~ ., data = oversampled_treino, laplace = 1)
# Verificar as variáveis usadas no modelo
vars_usadas <- names(nb_model$tables)
# Verificar as variáveis usadas
print(vars_usadas)
treino_restrito <- treino[, vars_usadas]
# Verificar se as variáveis estão corretas
print(colnames(treino_restrito))
# Prever com o modelo Naive Bayes usando apenas as variáveis relevantes
preditos_treino_nb <- predict(nb_model, newdata = treino_restrito, type = "class")
# Matriz de confusão para o conjunto de treino
conf_matrix_treino_nb <- confusionMatrix(data = preditos_treino_nb,
reference = treino$ativo,
positive = "1")
conf_matrix_treino_nb <- confusionMatrix(data = preditos_treino_nb,
reference = treino$ativo,
positive = "1",
levels = levels(preditos_treino_nb))
# Ajustar os níveis da variável de referência
treino$ativo <- factor(treino$ativo, levels = levels(preditos_treino_nb))
# Matriz de confusão para o conjunto de treino
conf_matrix_treino_nb <- confusionMatrix(data = preditos_treino_nb,
reference = treino$ativo,
positive = "1")
# Extração de precisão e recall da matriz de confusão
precision_treino_nb <- conf_matrix_treino_nb$byClass["Pos Pred Value"]  # Precisão
recall_treino_nb <- conf_matrix_treino_nb$byClass["Sensitivity"]        # Recall
# Imprimindo os resultados de precisão e recall
print(paste("Naive Bayes - Precisão (treino):", precision_treino_nb))
print(paste("Naive Bayes - Recall (treino):", recall_treino_nb))
# Avaliação na base de teste
preditos_teste_nb <- predict(nb_model, teste, type = "raw")
# Avaliação na base de teste
preditos_teste_nb <- predict(nb_model, teste, type = "prob")
# Prever classes com o modelo Naive Bayes
preditos_teste_nb <- predict(nb_model, newdata = teste, type = "class")
preditos_teste_nb <- predict(nb_model, newdata = teste, type = "prob")
source("C:/Users/NTB-073/Desktop/pós/TCC_churn/comparativo_churn.R")
